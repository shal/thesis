\chapter{Великі дані}

\section{Поняття великих даних}

Поняття великих даних з'явилося досить недавно.
Сервіс аналізу пошукових запитів у мережі Інтернет «Google Trends» демонструє початок активного росту
використання словосполучення починаючи з 2011 року.
Як ми бачимо на рис.~\ref{fig:big-data-search} піком актуальності теми великих даних був 2015 рік, проте
тема все ще залишається досить актуальною.
Тут простежується прямий зв'язок с початком розвитку сфери відкритих даних,
а тобто можна припустити, що з розвитком теми відкритих даних буде продовжуватися вивчення способів їх ефективної обробки.

Величезна кількість необроблених даних оточує нас у  світі \cite{BigDataFundamentals}.
Дані, які не можуть бути безпосередньо розглянуті людьми.
Інтернет, держава та бізнес генерують нові дані з неабиякою
швидкістю завдяки розробці потужних засобів зберігання та об'єднання
даних. Організовані дані чи інформація не можуть бути просто зрозумілі
або автоматично оброблені через їх величезну кількість та різноманіття.
Ці передумови призвели до розвитку науки про дані та
аналіз даних, відомої дисципліни, яка все більше і більше присутня в
сучасному інформаційному світі.

Сучасний обсяг даних, що керуються створеними людиною системами,
перевершує можливості обробки традиційних систем.
Виникнення нових технологій і послуг, а також зниження вартості обладнання призводять до постійно збільшення інформації в мережі «Інтернет».
Це явище, безумовно, є великим викликом для спільноти аналітиків даних.
Поняття великих даних може бути визначене як великий обсяг різноманітних даних, що вимагають нового підходу, а тобто більш ефективної обробки.

Розподілені обчислення широко використовувалися аналітиками даних до появи терміну великих даних.
Багато стандартних та складних алгоритмів були замінені їх паралельними версіями з метою зменшення
часу виконання програмного забезпечення, що витрачається на обробку даних.
Проте сьогодні, для більшості сучасних проблем, розподілений підхід стає обов'язковим, оскільки
жодна архітектура не може розв'язати усі ці проблеми.

Міжнародна компанія McKinsey,
що спеціалізується на вирішенні завдань,
пов'язаних зі стратегічним управлінням,
виділяє 5 методів і технік аналізу,
які можна застосувати до великих даних.

\textbf{Методи класу Data Mining} – сукупність методів виявлення в даних раніше невідомих, нетривіальних, п
рактично корисних знань, необхідних для прийняття рішень.
До таких методів, зокрема, відносяться навчання асоціативним правилами,
класифікація (розбиття на категорії), кластерний аналіз, регресійний аналіз,
виявлення та аналіз відхилень.

\textbf{Краудсорсинг} – класифікація і збагачення даних силами широкого,
невизначеного кола осіб,
які виконують цю роботу без вступу в трудові відносини.

\textbf{Змішування й інтеграція даних} – набір технік, що дозволяють інтегрувати різнорідні дані з
різноманітних джерел з метою проведення глибинного аналізу.
Наприклад, цифрова обробка сигналів, обробка природної мови та ін.

\textbf{Машинне навчання}, включаючи навчання з учителем і без вчителя —
використання моделей, побудованих на базі статистичного аналізу або машинного навчання для
отримання комплексних прогнозів на основі базових моделей.

\textbf{Візуалізація аналітичних даних} – подання інформації у вигляді малюнків, діаграм,
з використанням інтерактивних можливостей та анімації як для отримання результатів,
так і для використання як вихідних даних для подальшого аналізу.
Дуже важливий етап аналізу великих даних,
що дозволяє представити найважливіші результати аналізу в найбільш зручному для сприйняття виді.
Прикладом візуалізації даних у сфері українського транспорту є рис.~\ref{fig:transport-colors},
що демонструє просту діаграму розподілення кольорів транспорту.

Розглянемо основні принципи роботи з великими даними:

\textbf{Горизонтальна масштабованість} — базовий принцип обробки великих даних.
Як вже говорилося, великих даних з кожним днем cтає все більше.
Відповідно, необхідно збільшувати кількість обчислювальних вузлів,
за якими розподіляються ці дані,
причому обробка повинна відбуватися без погіршення ефективності.

\textbf{Відмовостійкість.} Цей принцип випливає з попереднього.
Оскільки обчислювальних вузлів в кластері може бути багато і їх кількість,
не виключено, буде збільшуватися, зростає і ймовірність виходу машин з ладу.
Методи роботи з великими даними повинні враховувати можливість
таких ситуацій і передбачати превентивні заходи.

\textbf{Локальність даних.} Оскільки дані розподілені на великій кількості обчислювальних вузлів,
то, якщо вони фізично знаходяться на одному сервері,
а обробляються на іншому, витрати на передачу даних можуть стати невиправдано великими.
Тому обробку даних бажано проводити на тій же машині, на якій вони зберігаються.
Ці принципи відрізняються від тих, які характерні для традиційних, централізованих, вертикальних моделей зберігання добре структурованих даних. Відповідно, для роботи з великими даними розробляють нові підходи й технології.
Підсумовуючи проаналізовано інформацію,
щодо поняття «Big Data», сформулюємо вичерпне визначення в рамках цієї роботи.

Big Data — набір підходів, інструментів і методів обробки структурованих і неструктурованих даних величезних обсягів і значного різноманіття з метою отримання зрозумілої для людини інформації, ефективної в умовах безперервного приросту.

\section{Технологія MapReduce}

У 2004 вченими корпорації «Google» було розроблено інноваційну технологію для розподілених обчислень \cite{GoogleMapReduce}.
MapReduce – це технологія для розподілених обчислень великих масивів даних.
Користувачі визначають так звану функцію Map, що обробляє
пари ключ/значення для створення набору проміжного результату, який у свою чергу отримує
так звана функція Reduce, головною ціллю якої є об'єднання усіх проміжних значень, пов'язаних з одним й тим самим проміжним ключем.
Величезна кількість справжніх задач можуть бути виражені за допомогою цієї моделі.

Програмне забезпечення, що написане у такому функціональному стилі,
може бути легко розбито на велику кількість паралельних операцій, тобто виконуватися одночасно на
великій кількості процесорів/машин.
Системи виконання програмних продуктів мають змогу займатися
тонкощами розбиття вхідних даних, плануванням виконання програми на декількох процесорах,
обробкою помилок і керуванням необхідних міжпроцесорних операцій комунікації.
Це дозволяє розробникам, що мають невеликий досвід роботи з паралельними
й розподіленими системами легко використовувати ресурси великих розподілених систем.

Працівники корпорації «Google» розробили тисячі спеціалізованих
інструментів, що обробляють великі обсяги необроблених даних,
проте більшість обчислень концептуально прості.
Через велику кількість вхідних даних, обчислення повинні бути розподілені на
сотні або тисячі паралельних одиниць для виконання роботи у розумний час.

Через складнощі з обробкою даних, кількість яких безперервно росте, вченими було розроблено нові абстракції, що дозволяють нам виконувати прості обчислення, але позбутися складнощів розпаралелювання, відмовостійкості, розподілу даних
та балансування навантаження. Створена абстракція надихається функціями Map та Reduce,
що присутні в багатьох функціональних мовах програмування.

Вчені зрозуміли, що в більшості обчислень залучали операції Map
до кожного логічного рядка у вхідних даних задля обчислення масивів проміжних пар ключ/значення,
та подальшого застосування операції Reduce до всіх спільних значень, щоб відповідним чином поєднати отримані дані.

Використання функціональної моделі з реалізованою користувачем операції Map та Reduce,
дозволяють легко розпаралелювати обчислення великих даних та
використовувати повторне виконання як основний механізм відмовостійкості \cite{DistributedSystems}.

Програмна модель приймає на вхід велику кількість пар ключ/значення, та повертає на вихід пари ключ-значення.
Так званий користувач «MapReduce» виражає обчислення як дві функції: Map та Reduce.

Функція Map, реалізована користувачем, приймає вхідну пару і виробляє набір проміжних пар ключ/значення.
Алгоритм об'єднає всі проміжні значення, пов'язані з одним й тим самим проміжним ключем, та передає їх
далі до функції Reduce.

Функція Reduce, також реалізована користувачем, приймає
проміжний ключ й набір значень для цього ключа.
Функція повинна об'єднати ці значення, щоб утворити менший набір значень.
Зазвичай нульове значення або одне вихідне значення
виробляється на кожному виклику Reduce.
Проміжні значення подаються до функції Reduce через ітератор.
Це дозволяє обробляти величезні масиви даних та
ефективно використовувати динамічну пам'ять.

В загальному випадку можливі різні реалізації інтерфейсу MapReduce.
Правильний вибір залежить від середовища виконання.
Наприклад, одна реалізація може підходити для сервера з
невеликою кількістю спільної пам'яті, інша реалізація для
кластерів з великою кількістю пам'яті та вузлів.
Виклики Map розподілені на декілька шляхом розбиття вхідних даних
у масив з M елементів.
Вхідні розбиття можуть оброблятися паралельно різними потоками.
Виклики Reduce розподілені шляхом розбиття проміжних пар ключ/значення
на R фрагментів з використанням функції розподілу (наприклад, F = hash(key) mod R}).
Кількість фрагментів R і  F користувачем.
На рис.~\ref{fig:map-reduce} показаний загальний потік дій у MapReduce.

В даному пункті був представлений загальний огляд технології
MapReduce та приклад її використання. У будь-якому випадку,
перед використанням технології необхідно розуміти для яких саме задач вона
призначена та чи доцільно її використовувати.
